{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JuJurado238/Prueba_Mercado_Libre/blob/main/Notebook_pruebaipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r ./requirements.txt --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-wqvl0wnusz",
        "outputId": "fe62ffec-8bb6-4f57-c6d8-033520dff674"
      },
      "id": "f-wqvl0wnusz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: './requirements.txt'\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "90Z4AwCY7UMg"
      },
      "id": "90Z4AwCY7UMg"
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLSSsU-Kp1UH",
        "outputId": "1bbd70a6-9142-479d-af08-10bfd876122f"
      },
      "id": "yLSSsU-Kp1UH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.12.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f41a5c57",
      "metadata": {
        "id": "f41a5c57",
        "outputId": "6db608ff-b05e-489d-c789-ea84cff64c4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-optimize in /usr/local/lib/python3.12/dist-packages (0.10.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (1.5.2)\n",
            "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (25.7.0)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (1.16.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (1.6.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (25.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "pip install scikit-optimize --use-deprecated=legacy-resolver"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GCb8QOsrnt9N"
      },
      "id": "GCb8QOsrnt9N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34563619",
      "metadata": {
        "id": "34563619"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78460fbe",
      "metadata": {
        "id": "78460fbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "2f78004c-2044-41ca-c291-7f554f119c91"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './MercadoLibre Inc. Data Scientist Hiring Test - Fraud Dataset  - Data.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3560371933.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m data=pd.read_csv('./MercadoLibre Inc. Data Scientist Hiring Test - Fraud Dataset  - Data.csv',delimiter=',',\n\u001b[0m\u001b[1;32m      2\u001b[0m     thousands=',' )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './MercadoLibre Inc. Data Scientist Hiring Test - Fraud Dataset  - Data.csv'"
          ]
        }
      ],
      "source": [
        "data=pd.read_csv('./MercadoLibre Inc. Data Scientist Hiring Test - Fraud Dataset  - Data.csv',delimiter=',',\n",
        "    thousands=',' )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "119ad1cb",
      "metadata": {
        "id": "119ad1cb"
      },
      "source": [
        "### Análisis exploratorio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3410018e",
      "metadata": {
        "id": "3410018e"
      },
      "outputs": [],
      "source": [
        "data['I'].sort_values(ascending=False)\n",
        "data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca5edb18",
      "metadata": {
        "id": "ca5edb18"
      },
      "outputs": [],
      "source": [
        "\n",
        "##Revisión de la variable para observar si se deb hacer trasnformaci+on logaritmica\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.kdeplot(data=data, x='L', hue='Fraude', fill=True, common_norm=False, alpha=0.4)\n",
        "plt.title('l')\n",
        "plt.xlabel('L')\n",
        "plt.ylabel('Densidad')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a97320e",
      "metadata": {
        "id": "1a97320e"
      },
      "outputs": [],
      "source": [
        "data.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ed45608",
      "metadata": {
        "id": "9ed45608"
      },
      "outputs": [],
      "source": [
        "print(data[['Q','R','Monto']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e0c65c6",
      "metadata": {
        "id": "9e0c65c6"
      },
      "outputs": [],
      "source": [
        "## Gráfico de barras para observar el desbalanceo\n",
        "conteo = data['Fraude'].value_counts()\n",
        "\n",
        "plt.figure(figsize=(7, 5))\n",
        "sns.countplot(x='Fraude', data=data, palette='coolwarm')\n",
        "plt.title('Distribución de Clases (Fraude vs. No Fraude)', fontsize=14)\n",
        "plt.xlabel('Clase', fontsize=12)\n",
        "plt.ylabel('Frecuencia', fontsize=12)\n",
        "plt.xticks([0, 1], ['No Fraude (0)', 'Fraude (1)'])\n",
        "for i, count in enumerate(conteo):\n",
        "    plt.text(i, count + 100, str(count), ha='center', va='bottom', fontsize=11)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "600f8395",
      "metadata": {
        "id": "600f8395"
      },
      "outputs": [],
      "source": [
        "#matrix de correlaciones\n",
        "#No se observa problemas de multolinealidad\n",
        "corr_matrix = data.corr(numeric_only=True)\n",
        "plt.figure(figsize=(18, 14))\n",
        "sns.heatmap(corr_matrix,\n",
        "            annot=True,\n",
        "            cmap='coolwarm',\n",
        "            center=0,\n",
        "            fmt=\".2f\",\n",
        "            linewidths=0.5,\n",
        "            cbar_kws={'label': 'Correlación'})\n",
        "\n",
        "plt.title('Matriz de correlación', fontsize=16)\n",
        "plt.xticks(rotation=45, ha='right', fontsize=10)\n",
        "plt.yticks(rotation=0, fontsize=10)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79e4df14",
      "metadata": {
        "id": "79e4df14"
      },
      "outputs": [],
      "source": [
        "##Valores de Paises\n",
        "print(data['J'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63c12c2b",
      "metadata": {
        "id": "63c12c2b"
      },
      "outputs": [],
      "source": [
        "##Conteo de paises\n",
        "## Se agrupan en 'Otros' locaciones por debajo de 10, para evitar sobredimesionar el data set\n",
        "conteo_paises = data['J'].value_counts()\n",
        "paises_raros = conteo_paises[conteo_paises < 10].index\n",
        "data['J_agrupado'] = data['J'].replace(paises_raros, 'Otros')\n",
        "print(data['J_agrupado'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a79cdd1",
      "metadata": {
        "id": "4a79cdd1"
      },
      "outputs": [],
      "source": [
        "# Aplicar OHE a la columna agrupada\n",
        "# Se elimina la columna K, al no tener conocimiento de lo que es y dado que\n",
        "data = pd.get_dummies(data, columns=['J_agrupado'], prefix='Pais')\n",
        "data.dtypes\n",
        "data=data.drop(columns=['J','K'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "595ba29a",
      "metadata": {
        "id": "595ba29a"
      },
      "outputs": [],
      "source": [
        "data.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04bc2be0",
      "metadata": {
        "id": "04bc2be0"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbf3158e",
      "metadata": {
        "id": "bbf3158e"
      },
      "outputs": [],
      "source": [
        "print(data['Monto'].value_counts())\n",
        "print(data['Q'].value_counts())\n",
        "print(data['R'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3a318eb",
      "metadata": {
        "id": "e3a318eb"
      },
      "outputs": [],
      "source": [
        "data['R'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44aa6078",
      "metadata": {
        "id": "44aa6078"
      },
      "outputs": [],
      "source": [
        "data['Q'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce947995",
      "metadata": {
        "id": "ce947995"
      },
      "outputs": [],
      "source": [
        "data.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "279c6a55",
      "metadata": {
        "id": "279c6a55"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "sns.histplot(data['C'], color='red', label='C', kde=True, stat='density')\n",
        "#sns.histplot(data['K'], color='blue', label='Sí operaron', kde=True, stat='density')\n",
        "plt.title('Distribución de C')\n",
        "plt.xlabel('C')\n",
        "plt.ylabel('Densidad')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82a4fc0e",
      "metadata": {
        "id": "82a4fc0e"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Dada la forma de la distribución de la Variable 'C' y teniendo en cuenta que tiene una pequeña cantidad de datos\n",
        "# faltantes, es correcto imputar estos con la mediana\n",
        "data['C'] = data['C'].fillna(data['C'].median())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f0d7abc",
      "metadata": {
        "id": "5f0d7abc"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "sns.histplot(data['Monto'], color='red', label='Monto', kde=True, stat='density')\n",
        "#sns.histplot(data['K'], color='blue', label='Sí operaron', kde=True, stat='density')\n",
        "plt.title('Distribución de Monto')\n",
        "plt.xlabel('Monto')\n",
        "plt.ylabel('Densidad')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afd90713",
      "metadata": {
        "id": "afd90713"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "sns.histplot(data['Q'], color='red', label='Q', kde=True, stat='density')\n",
        "#sns.histplot(data['K'], color='blue', label='Sí operaron', kde=True, stat='density')\n",
        "plt.title('Distribución de Q')\n",
        "plt.xlabel('Q')\n",
        "plt.ylabel('Densidad')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4c3ba00",
      "metadata": {
        "id": "a4c3ba00"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import math\n",
        "###detección de outliers\n",
        "#Criterio del Rango Intercuartílico (IQR)\n",
        "## se define outliers los valores que están por debajo del límite interior y por encima del superior\n",
        "numeric_df = data.select_dtypes(include='number')\n",
        "\n",
        "non_binary_cols = [\n",
        "    col for col in numeric_df.columns\n",
        "    if numeric_df[col].dropna().nunique() > 2\n",
        "]\n",
        "\n",
        "columns_with_outliers = []\n",
        "for col in non_binary_cols:\n",
        "    Q1 = numeric_df[col].quantile(0.25)\n",
        "    Q3 = numeric_df[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower = Q1 - 1.5 * IQR\n",
        "    upper = Q3 + 1.5 * IQR\n",
        "    outliers = numeric_df[(numeric_df[col] < lower) | (numeric_df[col] > upper)]\n",
        "    if not outliers.empty:\n",
        "        columns_with_outliers.append(col)\n",
        "\n",
        "\n",
        "n_cols = 3\n",
        "n_plots = len(columns_with_outliers)\n",
        "n_rows = math.ceil(n_plots / n_cols)\n",
        "\n",
        "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 3 * n_rows))\n",
        "axes = axes.flatten()\n",
        "\n",
        "\n",
        "for i, col in enumerate(columns_with_outliers):\n",
        "    sns.boxplot(x=data[col], ax=axes[i], linewidth=0.8, fliersize=2)\n",
        "    axes[i].set_title(col, fontsize=9)\n",
        "    axes[i].set_xlabel('')\n",
        "    axes[i].grid(True, linestyle='--', alpha=0.5)\n",
        "\n",
        "\n",
        "for j in range(i + 1, len(axes)):\n",
        "    fig.delaxes(axes[j])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "150b119e",
      "metadata": {
        "id": "150b119e"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import math\n",
        "\n",
        "\n",
        "# Aunque existen outliers los modleo de arboles que uso, pueden manenajr de manera correcta este tipo de datos\n",
        "##al hacer pruebas de modelos, usar la transformación logaritmica en 'Monto' logró mejorar la capacidad predictiva de estos\n",
        "non_binary_cols = [\n",
        "    col for col in numeric_df.columns\n",
        "    if numeric_df[col].dropna().nunique() > 2\n",
        "]\n",
        "\n",
        "columns_with_outliers = []\n",
        "outliers_dict = {}\n",
        "\n",
        "for col in non_binary_cols:\n",
        "    Q1 = numeric_df[col].quantile(0.25)\n",
        "    Q3 = numeric_df[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower = Q1 - 1.5 * IQR\n",
        "    upper = Q3 + 1.5 * IQR\n",
        "    outliers = numeric_df[(numeric_df[col] < lower) | (numeric_df[col] > upper)][col]\n",
        "    if not outliers.empty:\n",
        "        columns_with_outliers.append(col)\n",
        "        outliers_dict[col] = outliers\n",
        "\n",
        "\n",
        "n_cols = 3\n",
        "n_plots = len(columns_with_outliers)\n",
        "n_rows = math.ceil(n_plots / n_cols)\n",
        "\n",
        "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 3 * n_rows))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, col in enumerate(columns_with_outliers):\n",
        "\n",
        "    sns.kdeplot(data=numeric_df[col].dropna(), ax=axes[i], fill=True, linewidth=1.5, color='blue')\n",
        "\n",
        "\n",
        "    axes[i].scatter(outliers_dict[col], [0] * len(outliers_dict[col]), color='red', alpha=0.6, label='Outliers')\n",
        "\n",
        "    axes[i].set_title(f'Densidad con outliers: {col}', fontsize=9)\n",
        "    axes[i].grid(True, linestyle='--', alpha=0.4)\n",
        "    axes[i].legend(fontsize=7)\n",
        "\n",
        "\n",
        "for j in range(i + 1, len(axes)):\n",
        "    fig.delaxes(axes[j])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ca32e9d",
      "metadata": {
        "id": "5ca32e9d"
      },
      "source": [
        "\n",
        "$$\n",
        "\\mathbf{Ganancia} = \\sum_{i \\in \\text{Aprobadas}} \\left[ (0.25 \\times M_i) \\cdot \\mathbb{I}(y_{\\text{verdaderos}, i} = 0) - (1.0 \\times M_i) \\cdot \\mathbb{I}(y_{\\text{verdaderos}, i} = 1) \\right]\n",
        "$$\n",
        "\n",
        "\n",
        "$$\n",
        "\\mathbf{g_i = \\frac{\\partial L_i}{\\partial \\eta_i} = \\begin{cases} 0.25 \\cdot M_i \\cdot p_i & \\text{si } y_i = 0 \\text{ (No Fraude)} \\\\ -1.0 \\cdot M_i \\cdot (1 - p_i) & \\text{si } y_i = 1 \\text{ (Fraude)} \\end{cases}}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\mathbf{h_i = \\frac{\\partial^2 L_i}{\\partial \\eta_i^2} = \\begin{cases} 0.25 \\cdot M_i \\cdot p_i (1 - p_i) & \\text{si } y_i = 0 \\text{ (No Fraude)} \\\\ 1.0 \\cdot M_i \\cdot p_i (1 - p_i) & \\text{si } y_i = 1 \\text{ (Fraude)} \\end{cases}}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\mathbf{Ganacia_{total}} = \\left( 0.25 \\sum_{i \\in \\text{TN}} M_i \\right) - \\left( 1.0 \\sum_{i \\in \\text{FN}} M_i \\right)\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d117d42",
      "metadata": {
        "id": "4d117d42"
      },
      "outputs": [],
      "source": [
        "## Función Personlaizada para evaluar el modelo con respecto a necesidad de negocio\n",
        "\n",
        "def Ganancia(y_pred, dtrain):\n",
        "    \"\"\"\n",
        "    Función de pérdida diferenciada según el monto y tipo de error.\n",
        "    Penaliza más los fraudes aprobados y recompensa las transacciones legítimas aprobadas.\n",
        "    \"\"\"\n",
        "    y_true = dtrain.get_label()\n",
        "    ##Ponderación basado en la pérdida de la ganancia\n",
        "    monto = dtrain.get_weight()\n",
        "\n",
        "    # Probabilidad predicha (transformación sigmoide) para el gradiente\n",
        "    p = 1.0 / (1.0 + np.exp(-y_pred))\n",
        "\n",
        "    # Gradiente y Hessiano basados en pérdidas económicas necesario para XGboost\n",
        "    grad = np.where(\n",
        "        y_true == 1,  # Fraude\n",
        "        -monto * (1 - p),  # penalización fuerte si el modelo aprueba\n",
        "        -0.25 * monto * (0 - p)  # recompensa leve si aprueba verdaderos\n",
        "    )\n",
        "    #hessiano\n",
        "    hess = np.where(\n",
        "        y_true == 1,\n",
        "        monto * p * (1 - p),\n",
        "        0.25 * monto * p * (1 - p)\n",
        "    )\n",
        "    return grad, hess\n",
        "\n",
        "\n",
        "def ganancia_total(y_true, y_pred_proba, monto, threshold):\n",
        "\n",
        "    y_pred = (y_pred_proba >= threshold).astype(int)\n",
        "\n",
        "    ganancia = (\n",
        "\n",
        "     0.25 * monto[(y_pred == 0) & (y_true == 0)].sum()\n",
        "\n",
        "    - 1.0 * monto[(y_pred == 0) & (y_true == 1)].sum()\n",
        "\n",
        "     )\n",
        "\n",
        "    return ganancia\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a01e652",
      "metadata": {
        "id": "4a01e652"
      },
      "source": [
        "### Modelo xgboost, con función de gananacia total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f20febe",
      "metadata": {
        "id": "0f20febe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns # Necesario para la visualización gráfica de la matriz de confusión\n",
        "from xgboost import XGBClassifier, DMatrix, train\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report\n",
        "\n",
        "\n",
        "X = data.drop(['Fraude'], axis=1)\n",
        "\n",
        "y = data['Fraude']\n",
        "monto = data['Monto'].copy()\n",
        "## Split con estratificación\n",
        "X_train, X_test, y_train, y_test, monto_train, monto_test = train_test_split(\n",
        "    X, y, monto, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "\n",
        "# Entrenamiento\n",
        "\n",
        "dtrain = DMatrix(X_train, label=y_train, weight=monto_train)\n",
        "dtest = DMatrix(X_test, label=y_test, weight=monto_test)\n",
        "\n",
        "params = {\n",
        "    'objective': 'binary:logistic',\n",
        "    'eval_metric': 'auc',\n",
        "    'max_depth': 5,\n",
        "    'eta': 0.05,\n",
        "    'subsample': 0.8,\n",
        "    'colsample_bytree': 0.8,\n",
        "    'seed': 42\n",
        "}\n",
        "\n",
        "evallist = [(dtrain, 'train'), (dtest, 'eval')]\n",
        "\n",
        "model = train(\n",
        "    params,\n",
        "    dtrain,\n",
        "    num_boost_round=380,\n",
        "    obj=Ganancia, ## Aplicación de la función customizada\n",
        "    evals=evallist,\n",
        "    early_stopping_rounds=50, # Detiene el entrenamiento si no hay mejora en 50 rondas\n",
        "    verbose_eval=50\n",
        ")\n",
        "## Predicciones y Ganancia teniendo en cuenta el umbral que maximiza esta ganancia\n",
        "\n",
        "y_pred_proba = model.predict(dtest)\n",
        "\n",
        "\n",
        "##200 posibles umbrales\n",
        "umbrales = np.linspace(0.01, 0.99, 200)\n",
        "ganancias = [ganancia_total(y_test, y_pred_proba, monto_test, t) for t in umbrales]\n",
        "\n",
        "t_opt = umbrales[np.argmax(ganancias)]\n",
        "gan_max = max(ganancias)\n",
        "\n",
        "print(f\"\\n Umbral óptimo (ganancia): {t_opt:.3f}\")\n",
        "print(f\" Ganancia máxima esperada: ${gan_max:,.0f}\")\n",
        "\n",
        "\n",
        "y_pred_final = (y_pred_proba >= t_opt).astype(int)\n",
        "auc = roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "print(f\"\\nAUC-ROC: {auc:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "# Calcula la matriz de confusión\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_final)\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "\n",
        "sns.heatmap(\n",
        "    conf_matrix,\n",
        "    annot=True,\n",
        "    fmt='d',\n",
        "    cmap='Blues',\n",
        "    linewidths=.5,\n",
        "    cbar=False,\n",
        "    xticklabels=['Pred: No Fraude (0)', 'Pred: Fraude (1)'],\n",
        "    yticklabels=['Real: No Fraude (0)', 'Real: Fraude (1)']\n",
        ")\n",
        "plt.title('Matriz de Confusión Xgboost, con función de ganancia')\n",
        "plt.ylabel('Valores Reales ')\n",
        "plt.xlabel('Predicciones del Modelo ')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nReporte de Clasificación:\")\n",
        "print(classification_report(y_test, y_pred_final, target_names=['No Fraude', 'Fraude']))\n",
        "\n",
        "##Grafica de la ganancia\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(umbrales, ganancias)\n",
        "plt.axvline(x=t_opt, color='red', linestyle='--', label=f'Umbral óptimo = {t_opt:.3f}')\n",
        "plt.xlabel('Umbral de decisión')\n",
        "plt.ylabel('Ganancia total ($)')\n",
        "plt.title('Ganancia esperada vs Umbral xgboost normal')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6963add",
      "metadata": {
        "id": "a6963add"
      },
      "source": [
        "### Random Forest con Optimización Bayesiana"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6000d8d",
      "metadata": {
        "id": "c6000d8d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report, make_scorer, RocCurveDisplay\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real, Integer\n",
        "\n",
        "\n",
        "\n",
        "# Usamos AUC-ROC como métrica de CV para BayesSearchCV, ya que RF no admite custom loss.\n",
        "scorer_auc = make_scorer(roc_auc_score, needs_proba=True)\n",
        "\n",
        "# Definición del espacio de búsqueda para Random Forest\n",
        "param_space = {\n",
        "    'n_estimators': Integer(100, 500),\n",
        "    'max_depth': Integer(5, 15),\n",
        "    'min_samples_split': Integer(2, 20),\n",
        "    'min_samples_leaf': Integer(1, 10),\n",
        "    'class_weight': ['balanced', None]\n",
        "}\n",
        "\n",
        "# Inicializar Random Forest con hiperparámetros base\n",
        "rf_base = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Inicializar Optimización Bayesiana\n",
        "opt = BayesSearchCV(\n",
        "    rf_base,\n",
        "    param_space,\n",
        "    n_iter=30, # Número total de iteraciones de búsqueda\n",
        "    cv=5,      # 5-fold Cross-Validation\n",
        "    scoring=scorer_auc,\n",
        "    random_state=42,\n",
        "    n_jobs=-1  # Usar todos los cores\n",
        ")\n",
        "\n",
        "print(\"Iniciando Optimización Bayesiana para Random Forest...\")\n",
        "opt.fit(X_train, y_train)\n",
        "\n",
        "# Mejor modelo RF\n",
        "rf_model = opt.best_estimator_\n",
        "print(f\" Mejores Hiperparámetros RF (Bayesiana): {opt.best_params_}\")\n",
        "print(f\" Mejor AUC de CV (Bayesiana): {opt.best_score_:.4f}\")\n",
        "\n",
        "\n",
        "#  Predicciones y optimización en test\n",
        "\n",
        "\n",
        "y_pred_proba_rf = rf_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calcular Ganancia para todos los umbrales en el set de test\n",
        "umbrales = np.linspace(0.01, 0.99, 200)\n",
        "ganancias_rf = [ganancia_total(y_test, y_pred_proba_rf, monto_test, t) for t in umbrales]\n",
        "\n",
        "t_opt_rf = umbrales[np.argmax(ganancias_rf)]\n",
        "gan_max_rf = max(ganancias_rf)\n",
        "\n",
        "print(f\"\\n Umbral óptimo RF (ganancia en test): {t_opt_rf:.3f}\")\n",
        "print(f\" Ganancia máxima esperada RF: ${gan_max_rf:,.0f}\")\n",
        "\n",
        "#Evaluación de gráficos\n",
        "\n",
        "y_pred_final_rf = (y_pred_proba_rf >= t_opt_rf).astype(int)\n",
        "auc_rf = roc_auc_score(y_test, y_pred_proba_rf)\n",
        "\n",
        "print(f\"\\nAUC-ROC RF (test): {auc_rf:.4f}\")\n",
        "\n",
        "\n",
        "plt.figure(figsize=(7, 7))\n",
        "# RocCurveDisplay.from_estimator requiere el modelo entrenado, pero aquí usamos las probabilidades predichas\n",
        "# La forma más simple es usar los datos ya calculados.\n",
        "RocCurveDisplay.from_predictions(y_test, y_pred_proba_rf, ax=plt.gca(), name=f\"Random Forest (AUC: {auc_rf:.4f})\")\n",
        "plt.title('Curva ROC')\n",
        "plt.grid(linestyle='--', alpha=0.6)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nReporte de Clasificación RF:\")\n",
        "print(classification_report(y_test, y_pred_final_rf, target_names=['No Fraude', 'Fraude']))\n",
        "\n",
        "\n",
        "\n",
        "#Gráfico de la Matriz de Confusión (Heatmap)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_final_rf)\n",
        "labels = ['No Fraude (0)', 'Fraude (1)']\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(\n",
        "    conf_matrix,\n",
        "    annot=True,\n",
        "    fmt='d',\n",
        "    cmap='Blues',\n",
        "    cbar=False,\n",
        "    xticklabels=labels,\n",
        "    yticklabels=labels\n",
        ")\n",
        "plt.title(f'Matriz de Confusión RF (Umbral={t_opt_rf:.3f})')\n",
        "plt.ylabel('Valores Reales (True)')\n",
        "plt.xlabel('Predicciones del Modelo (Predicted)')\n",
        "plt.show()\n",
        "\n",
        "## 6.2 Gráfico de la Ganancia vs Umbral\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(umbrales, ganancias_rf)\n",
        "plt.axvline(x=t_opt_rf, color='red', linestyle='--', label=f'Umbral óptimo = {t_opt_rf:.3f}')\n",
        "plt.xlabel('Umbral de decisión')\n",
        "plt.ylabel('Ganancia total ($)')\n",
        "plt.title('RF: Ganancia esperada vs Umbral (optimizado con Bayes)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b091a0a1",
      "metadata": {
        "id": "b091a0a1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from xgboost import XGBClassifier, DMatrix, train\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report, make_scorer, RocCurveDisplay\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real, Integer\n",
        "\n",
        "\n",
        "monto = data['Monto'].copy() # Monto REAL para la ganancia/pérdida\n",
        "\n",
        "# Split con estratificación\n",
        "X_train, X_test, y_train, y_test, monto_train, monto_test = train_test_split(\n",
        "    X, y, monto, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "\n",
        "# ======================================================\n",
        "# 1️⃣ OPTIMIZACIÓN BAYESIANA DE HIPERPARÁMETROS (XGBoost)\n",
        "# ======================================================\n",
        "\n",
        "scorer_auc = make_scorer(roc_auc_score, needs_proba=True)\n",
        "\n",
        "# Espacio de búsqueda para XGBoost (ajustado para que sea más realista)\n",
        "param_space_xgb = {\n",
        "    'n_estimators': Integer(100, 600),\n",
        "    'max_depth': Integer(3, 10),\n",
        "    'learning_rate': Real(0.01, 0.1, prior='log-uniform'),\n",
        "    'subsample': Real(0.7, 1.0, prior='uniform'),\n",
        "    'colsample_bytree': Real(0.7, 1.0, prior='uniform'),\n",
        "}\n",
        "\n",
        "xgb_base = XGBClassifier(objective='binary:logistic', eval_metric='auc', use_label_encoder=False, random_state=42)\n",
        "\n",
        "opt_xgb = BayesSearchCV(\n",
        "    xgb_base,\n",
        "    param_space_xgb,\n",
        "    n_iter=30,\n",
        "    cv=3,       # Reducido a cv=3 para mayor velocidad en el ejemplo\n",
        "    scoring=scorer_auc,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "print(\"Iniciando Optimización Bayesiana para XGBoost (usando AUC)...\")\n",
        "# Usamos fit() con los datos de entrenamiento\n",
        "opt_xgb.fit(X_train, y_train)\n",
        "\n",
        "# Resultados de la Optimización Bayesiana\n",
        "best_params_xgb = opt_xgb.best_params_\n",
        "print(f\" Mejores Hiperparámetros XGBoost (Bayesiana): {best_params_xgb}\")\n",
        "print(f\" Mejor AUC (Bayesiana): {opt_xgb.best_score_:.4f}\")\n",
        "\n",
        "# ======================================================\n",
        "# 2️⃣ ENTRENAMIENTO FINAL (CON CUSTOM LOSS Y PARÁMETROS ÓPTIMOS)\n",
        "# ======================================================\n",
        "\n",
        "# Creamos los DMatrix necesarios\n",
        "dtrain = DMatrix(X_train, label=y_train, weight=monto_train)\n",
        "dtest = DMatrix(X_test, label=y_test, weight=monto_test)\n",
        "\n",
        "# Parámetros finales (incluimos los óptimos encontrados por BayesSearchCV)\n",
        "params_final = {\n",
        "    'objective': 'binary:logistic',\n",
        "    'eval_metric': 'auc',\n",
        "    'use_label_encoder': False,\n",
        "    'random_state': 42,\n",
        "    **best_params_xgb # Desempaquetar los mejores hiperparámetros\n",
        "}\n",
        "\n",
        "model_final = train(\n",
        "    params_final,\n",
        "    dtrain,\n",
        "    num_boost_round=params_final['n_estimators'], # Usar el n_estimators óptimo\n",
        "    obj=Ganancia, # Usamos la función de pérdida económica\n",
        "    evals=[(dtest, 'eval')],\n",
        "    early_stopping_rounds=20,\n",
        "    verbose_eval=False\n",
        ")\n",
        "\n",
        "# Resultados de la Predicción Final\n",
        "y_pred_proba_final = model_final.predict(dtest)\n",
        "\n",
        "# Calcular Ganancia para todos los umbrales en el set de TEST\n",
        "umbrales = np.linspace(0.01, 0.99, 200)\n",
        "ganancias_final = [ganancia_total(y_test, y_pred_proba_final, monto_test, t) for t in umbrales]\n",
        "\n",
        "t_opt_final = umbrales[np.argmax(ganancias_final)]\n",
        "gan_max_final = max(ganancias_final)\n",
        "\n",
        "print(f\"\\n💰 Umbral óptimo XGBoost (ganancia en test): {t_opt_final:.3f}\")\n",
        "print(f\"💰 Ganancia máxima esperada XGBoost: ${gan_max_final:,.0f}\")\n",
        "\n",
        "\n",
        "# ======================================================\n",
        "# 3️⃣ EVALUACIÓN Y VISUALIZACIÓN FINAL DEL MODELO XGBOOST\n",
        "# ======================================================\n",
        "\n",
        "y_pred_final_xgb = (y_pred_proba_final >= t_opt_final).astype(int)\n",
        "auc_xgb = roc_auc_score(y_test, y_pred_proba_final)\n",
        "\n",
        "print(f\"\\nAUC-ROC XGBoost (test): {auc_xgb:.4f}\")\n",
        "\n",
        "# --- 3.1 Gráfico de la Curva ROC (AUC) ---\n",
        "plt.figure(figsize=(7, 7))\n",
        "RocCurveDisplay.from_predictions(y_test, y_pred_proba_final, ax=plt.gca(), name=f\"XGBoost (AUC: {auc_xgb:.4f})\")\n",
        "plt.title('Curva ROC - XGBoost con OB')\n",
        "plt.grid(linestyle='--', alpha=0.6)\n",
        "plt.show()\n",
        "\n",
        "# --- 3.2 Matriz de Confusión Gráfica (Heatmap) ---\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_final_xgb)\n",
        "labels = ['No Fraude (0)', 'Fraude (1)']\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(\n",
        "    conf_matrix,\n",
        "    annot=True,\n",
        "    fmt='d',\n",
        "    cmap='Blues',\n",
        "    cbar=False,\n",
        "    xticklabels=labels,\n",
        "    yticklabels=labels\n",
        ")\n",
        "plt.title(f'Matriz de Confusión XGBoost con OB (Umbral={t_opt_final:.3f})')\n",
        "plt.ylabel('Valores Reales (True)')\n",
        "plt.xlabel('Predicciones del Modelo (Predicted)')\n",
        "plt.show()\n",
        "\n",
        "# --- 3.3 Reporte de Clasificación ---\n",
        "print(\"\\nReporte de Clasificación XGBoost:\")\n",
        "print(classification_report(y_test, y_pred_final_xgb, target_names=['No Fraude', 'Fraude']))\n",
        "\n",
        "# --- 3.4 Visualizar Ganancia vs Umbral ---\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(umbrales, ganancias_final)\n",
        "plt.axvline(x=t_opt_final, color='red', linestyle='--', label=f'Umbral óptimo = {t_opt_final:.3f}')\n",
        "plt.xlabel('Umbral de decisión')\n",
        "plt.ylabel('Ganancia total ($)')\n",
        "plt.title('XGBoost: Ganancia esperada vs Umbral (Optimización Bayes)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e561452",
      "metadata": {
        "id": "4e561452"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}